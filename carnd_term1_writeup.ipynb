{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lane Lines on the Road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I'm going to identify lane lines on the road. The lane lines could be white or yellow in color. The distance between dashed lane lines also needs to be accounted. The lane lines may have the shadow of nearby objects like trees on them.\n",
    "\n",
    "Following are some of the images used for testing the pipeline:\n",
    "<table style=\"text-align:center;font-size:11pt\">\n",
    "<tr>\n",
    "<td><img src=\"./test_images/solidWhiteCurve.jpg\" width=\"420\" alt=\"White lane lines\" style=\"display:block\"/>Img1: White lane lines</td>\n",
    "<td><img src=\"./test_images/whiteCarLaneSwitch.jpg\" width=\"420\" alt=\"Yellow lane lines\" style=\"display:block\"/>Img2: Yellow lane lines</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images/solidWhiteRight.jpg\" width=\"420\" alt=\"Another white lane\" style=\"display:block\"/>Img3: Another white lane</td>\n",
    "<td><img src=\"./test_images/lane_test3.jpg\" width=\"420\" alt=\"Shaded yellow lane\" style=\"display:block\"/>Img4: Shaded yellow lane</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images/lane_test4.jpg\" width=\"420\" alt=\"Changing road color\" style=\"display:block\"/>Img5: Changing road color</td>\n",
    "<td><img src=\"./test_images/lane_test7.jpg\" width=\"420\" alt=\"Shaded yellow lane with changing road color\" style=\"display:block\"/>Img6: Shaded yellow lane with changing road color</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline consists of 6 steps:\n",
    "1. Decide optimal color thresholds\n",
    "2. Decide region of interest\n",
    "3. Mask out unwanted colors and region\n",
    "4. Detect edges in masked image\n",
    "5. Apply Hough transform to get the lines for edges\n",
    "6. Average the lines to get two lane lines and overlay on original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decide optimal color thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color thresholds for each of red, green and blue color are decide by using the following formula:\n",
    "\$$\n",
    "colorThreshold = regularColorThreshold - \\frac{(regularMedianColor - imageColorMedian)}{effectFactor}\n",
    "\$$\n",
    "Here *regularColorThreshold* is the threshold color value chosen for an image having median color equal to *regularMedianColor* approximately. *imageColorMedian* is the median of a color in current image. *effectFactor* is used to decide the effect of difference between color median of current and standard image on the regular threshold value.\n",
    "\n",
    "This formula could help to calibrate the color intensities moderately in different lighting conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decide region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region of interest is the triangular region starting from the base of the image extending to half of the height of image. Lane lines are identified inside this region only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mask out unwanted colors and region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the color and region thresholds are decided, now is the time to mask out the unwanted colors and region. Every pixel in image which has color intensity less than threshold is made black in color. All the pixels which fall out of the region of interest are also made black.\n",
    "\n",
    "Following are the images after masking out the unwanted colors and area:\n",
    "<table style=\"text-align:center;font-size:11pt\">\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/roi/solidWhiteCurve.jpg\" width=\"420\" alt=\"White lane lines\" style=\"display:block\"/>Img1: White lane lines</td>\n",
    "<td><img src=\"./test_images_output/roi/whiteCarLaneSwitch.jpg\" width=\"420\" alt=\"Yellow lane lines\" style=\"display:block\"/>Img2: Yellow lane lines</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/roi/solidWhiteRight.jpg\" width=\"420\" alt=\"Another white lane\" style=\"display:block\"/>Img3: Another white lane</td>\n",
    "<td><img src=\"./test_images_output/roi/lane_test3.jpg\" width=\"420\" alt=\"Shaded yellow lane\" style=\"display:block\"/>Img4: Shaded yellow lane</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/roi/lane_test4.jpg\" width=\"420\" alt=\"Changing road color\" style=\"display:block\"/>Img5: Changing road color</td>\n",
    "<td><img src=\"./test_images_output/roi/lane_test7.jpg\" width=\"420\" alt=\"Shaded yellow lane with changing road color\" style=\"display:block\"/>Img6: Shaded yellow lane with changing road color</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Detect edges in masked image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images, as seen above are now passed through canny edge detection function to get the image of edges. The image is blurred using gaussain blur algorithm before edged detection. Low and high thresholds for canny algorithm are calculated by taking median of single channel pixel intensities.\n",
    "\n",
    "Following is the formula used:\n",
    "$$\n",
    "low\\_threshold = \\begin{cases}\n",
    "    0                   & \\quad \\text{if } ((1.0 - sigma) * m) < 0\\\\\n",
    "    (1.0 - sigma) * m   & \\quad \\text{if } ((1.0 - sigma) * m) >= 0\n",
    "  \\end{cases}\n",
    "$$<br>\n",
    "$$\n",
    "high\\_threshold = \\begin{cases}\n",
    "    255                 & \\quad \\text{if } ((1.0 + sigma) * m) > 255\\\\\n",
    "    (1.0 + sigma) * m   & \\quad \\text{if } ((1.0 + sigma) * m) <= 255\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Here, _sigma_ is a constant whose value is taken as 0.33 for optimal results.\n",
    "_m_ is the median of single channel pixel intensities in the image.\n",
    "Following is the implementation of auto threshold canny function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_threshold_canny(original_image, src_image):\n",
    "    \"\"\" Compute the median of the single channel pixel intensities and\n",
    "        use it to determine low and high thresholds for canny edge detection function.\n",
    "    \"\"\"\n",
    "    m = np.median(original_image)\n",
    "    sigma=0.33\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    low_threshold = int(max(0, (1.0 - sigma) * m))\n",
    "    high_threshold = int(min(255, (1.0 + sigma) * m))\n",
    "    return canny(src_image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the images after edge detection:\n",
    "<table style=\"text-align:center;font-size:11pt\">\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/edges/solidWhiteCurve.jpg\" width=\"420\" alt=\"White lane lines\" style=\"display:block\"/>Img1: White lane lines</td>\n",
    "<td><img src=\"./test_images_output/edges/whiteCarLaneSwitch.jpg\" width=\"420\" alt=\"Yellow lane lines\" style=\"display:block\"/>Img2: Yellow lane lines</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/edges/solidWhiteRight.jpg\" width=\"420\" alt=\"Another white lane\" style=\"display:block\"/>Img3: Another white lane</td>\n",
    "<td><img src=\"./test_images_output/edges/lane_test3.jpg\" width=\"420\" alt=\"Shaded yellow lane\" style=\"display:block\"/>Img4: Shaded yellow lane</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/edges/lane_test4.jpg\" width=\"420\" alt=\"Changing road color\" style=\"display:block\"/>Img5: Changing road color</td>\n",
    "<td><img src=\"./test_images_output/edges/lane_test7.jpg\" width=\"420\" alt=\"Shaded yellow lane with changing road color\" style=\"display:block\"/>Img6: Shaded yellow lane with changing road color</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Apply Hough transform to get the lines for edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hough transform is used on the edge detected images to draw lines parallel to the lanes. Parameters for hough transform are set so that smaller lines with wider gap are also merged into a single line. That helps to detect dashed lane lines with wider gap between them due to any reason in the image.\n",
    "\n",
    "To draw lines, default `draw_lines` function is used directly on a copy of the original image.\n",
    "\n",
    "Following are the images after drawing lines on copy of original image:\n",
    "<table style=\"text-align:center;font-size:11pt\">\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/hough_lines/solidWhiteCurve.jpg\" width=\"420\" alt=\"White lane lines\" style=\"display:block\"/>Img1: White lane lines</td>\n",
    "<td><img src=\"./test_images_output/hough_lines/whiteCarLaneSwitch.jpg\" width=\"420\" alt=\"Yellow lane lines\" style=\"display:block\"/>Img2: Yellow lane lines</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/hough_lines/solidWhiteRight.jpg\" width=\"420\" alt=\"Another white lane\" style=\"display:block\"/>Img3: Another white lane</td>\n",
    "<td><img src=\"./test_images_output/hough_lines/lane_test3.jpg\" width=\"420\" alt=\"Shaded yellow lane\" style=\"display:block\"/>Img4: Shaded yellow lane</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/hough_lines/lane_test4.jpg\" width=\"420\" alt=\"Changing road color\" style=\"display:block\"/>Img5: Changing road color</td>\n",
    "<td><img src=\"./test_images_output/hough_lines/lane_test7.jpg\" width=\"420\" alt=\"Shaded yellow lane with changing road color\" style=\"display:block\"/>Img6: Shaded yellow lane with changing road color</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Average the lines to get two lane lines and overlay on original image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is visible in the above images, the lines returned from hough transform are not aligned properly on the actual lanes because of noise or other factors in edge detected image. So these lines need to be averaged and extrapolated so as to cover entire lane line.\n",
    "\n",
    "For averaging, slope, intercept and length of the detected lines are calculated using the equation of line: $y = mx + c$.\n",
    "Length of the line is calculated using the formula: $length = \\sqrt{(y2-y1)^2 + (x2-x1)^2}$.\n",
    "Where `x1, y1` and `x2, y2` are the coordinates of lines returned by hough transform function.\n",
    "\n",
    "Lines are averaged by calculating weighted averages for slopes and intercepts using length of lines as respective weights for positive and negative slopes. The lines drawn using averaged slope and intercept is the output.\n",
    "\n",
    "Following images are the output of this pipeline:\n",
    "<table style=\"text-align:center;font-size:11pt\">\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/output/solidWhiteCurve.jpg\" width=\"420\" alt=\"White lane lines\" style=\"display:block\"/>Img1: White lane lines</td>\n",
    "<td><img src=\"./test_images_output/output/whiteCarLaneSwitch.jpg\" width=\"420\" alt=\"Yellow lane lines\" style=\"display:block\"/>Img2: Yellow lane lines</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/output/solidWhiteRight.jpg\" width=\"420\" alt=\"Another white lane\" style=\"display:block\"/>Img3: Another white lane</td>\n",
    "<td><img src=\"./test_images_output/output/lane_test3.jpg\" width=\"420\" alt=\"Shaded yellow lane\" style=\"display:block\"/>Img4: Shaded yellow lane</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"./test_images_output/output/lane_test4.jpg\" width=\"420\" alt=\"Changing road color\" style=\"display:block\"/>Img5: Changing road color</td>\n",
    "<td><img src=\"./test_images_output/output/lane_test7.jpg\" width=\"420\" alt=\"Shaded yellow lane with changing road color\" style=\"display:block\"/>Img6: Shaded yellow lane with changing road color</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Modifications for Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finding lanes in a video, most part of the pipeline remains same except for the averaging part before the final lines are drawn. There might be some of the following issues in processing the video:\n",
    "1. minute glitches in individual frames due to noise, which could lead to flickering in the annotated lines in the output\n",
    "2. possibility that hough tranform did not return any line for positive and/or negative slopes\n",
    "\n",
    "So, to prevent these problems, averaging across past frames is also done after averaging hough lines for current frame.\n",
    "\n",
    "But, simple averaging of annotation lines across past frames might lead to slightly inaccurate slope of these lines. To prevent that weighted average is used. Weights are taken in order of occurence of past 5 frames, i.e, if wieght of current frame is `5`, then weight of fifth last frame will be `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the output for video `challenge.mp4`.\n",
    "\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"./test_videos_output/challenge.mp4\">\n",
    "Your browser does not support the video tag.\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click to download: https://github.com/rahul1593/CarND_Term1_Finding_Lanes/blob/master/test_videos_output/challenge.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Shortcomings of current pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the potential shortcomings which current pipeline doesn't address:\n",
    "* The current pipeline works fine in average lighting conditions. Results might be totally different in low light\n",
    "* The extrapolated lines are one third of the image height and region of interest is half of the image height, which may not work for up down roads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvements in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following improvements could be made in the current pipeline:\n",
    "* Considering the color of the road to predict the presence of road. This would eliminate the need for having hard coded region of interest\n",
    "* Color spaces other than RGB, like HSV, could be used to improve the detection of yellow and white color in different lighting conditions.\n",
    "* Grayscale image of original image can be used to improve performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
